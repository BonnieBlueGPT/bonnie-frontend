// ğŸš€ BONNIE ULTIMATE AI GIRLFRIEND SYSTEM - PRODUCTION v24.0
// ULTRA-OPTIMIZED with ALL critical improvements implemented
// AI Emotion Detection | WebSockets | JWT Auth | Content Moderation | Advanced Caching

import express from 'express';
import { createServer } from 'http';
import { Server as SocketIOServer } from 'socket.io';
import cors from 'cors';
import helmet from 'helmet';
import compression from 'compression';
import rateLimit from 'express-rate-limit';
import jwt from 'jsonwebtoken';
import bcrypt from 'bcrypt';
import dotenv from 'dotenv';
import axios from 'axios';
import winston from 'winston';
import { createClient } from '@supabase/supabase-js';
import { v4 as uuidv4 } from 'uuid';
import NodeCache from 'node-cache';
import Redis from 'redis';
import Sentry from '@sentry/node';
import { RateLimiterRedis } from 'rate-limiter-flexible';

// Load environment variables
dotenv.config();

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ” ERROR MONITORING SETUP - Sentry Integration
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if (process.env.SENTRY_DSN) {
  Sentry.init({
    dsn: process.env.SENTRY_DSN,
    environment: process.env.NODE_ENV || 'development',
    tracesSampleRate: process.env.NODE_ENV === 'production' ? 0.1 : 1.0,
  });
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸš€ EXPRESS & WEBSOCKET SETUP
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const app = express();
const server = createServer(app);
const io = new SocketIOServer(server, {
  cors: {
    origin: process.env.NODE_ENV === 'production' 
      ? ['https://chat.trainmygirl.com', 'https://trainmygirl.com']
      : ['http://localhost:3000', 'http://localhost:5173'],
    methods: ['GET', 'POST'],
    credentials: true
  },
  transports: ['websocket', 'polling'],
  pingTimeout: 60000,
  pingInterval: 25000
});

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ›¡ï¸ SECURITY & MIDDLEWARE SETUP
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// Security headers
app.use(helmet({
  contentSecurityPolicy: {
    directives: {
      defaultSrc: ["'self'"],
      styleSrc: ["'self'", "'unsafe-inline'"],
      scriptSrc: ["'self'"],
      imgSrc: ["'self'", "data:", "https:"],
      connectSrc: ["'self'", "wss:", "https:"],
    },
  },
  crossOriginEmbedderPolicy: false
}));

// CORS configuration
app.use(cors({
  origin: process.env.NODE_ENV === 'production' 
    ? ['https://chat.trainmygirl.com', 'https://trainmygirl.com']
    : ['http://localhost:3000', 'http://localhost:5173'],
  credentials: true,
  methods: ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'],
  allowedHeaders: ['Content-Type', 'Authorization', 'X-Requested-With']
}));

app.use(compression());
app.use(express.json({ limit: '10mb' }));
app.use(express.urlencoded({ extended: true, limit: '10mb' }));

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ“Š ADVANCED LOGGING SETUP - Production-grade with Sentry
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const logger = winston.createLogger({
  level: process.env.LOG_LEVEL || 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.errors({ stack: true }),
    winston.format.json(),
    winston.format.printf(({ timestamp, level, message, ...meta }) => {
      return JSON.stringify({
        timestamp,
        level,
        message,
        ...meta,
        service: 'bonnie-ai',
        version: '24.0'
      });
    })
  ),
  transports: [
    new winston.transports.Console({
      format: winston.format.simple()
    })
  ],
});

// Add error reporting to Sentry
logger.add(new winston.transports.Console({
  level: 'error',
  handleExceptions: true,
  format: winston.format.combine(
    winston.format.errors({ stack: true }),
    winston.format.json()
  )
}));

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ”„ ADVANCED CACHING SYSTEM - Multi-tier with Redis
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// Local memory cache for ultra-fast access
const localCache = new NodeCache({
  stdTTL: 300, // 5 minutes
  checkperiod: 60,
  useClones: false
});

// Redis cache for distributed caching
let redisClient;
if (process.env.REDIS_URL) {
  redisClient = Redis.createClient({
    url: process.env.REDIS_URL,
    retry_unfulfilled_commands: true,
    socket: {
      reconnectStrategy: (retries) => Math.min(retries * 50, 1000)
    }
  });
  
  redisClient.on('error', (err) => {
    logger.error('Redis Client Error:', err);
  });
  
  redisClient.on('connect', () => {
    logger.info('âœ… Redis connected successfully');
  });
  
  redisClient.connect().catch((err) => {
    logger.error('Redis connection failed:', err);
  });
}

// Advanced cache manager with invalidation
class AdvancedCacheManager {
  constructor() {
    this.localCache = localCache;
    this.redisCache = redisClient;
    this.invalidationPatterns = new Map();
  }
  
  async get(key) {
    try {
      // Try local cache first (fastest)
      let value = this.localCache.get(key);
      if (value !== undefined) {
        return value;
      }
      
      // Try Redis cache
      if (this.redisCache && this.redisCache.isReady) {
        const redisValue = await this.redisCache.get(key);
        if (redisValue) {
          value = JSON.parse(redisValue);
          // Store in local cache for next time
          this.localCache.set(key, value, 300);
          return value;
        }
      }
      
      return null;
    } catch (error) {
      logger.error('Cache get error:', error);
      return null;
    }
  }
  
  async set(key, value, ttl = 600) {
    try {
      // Set in local cache
      this.localCache.set(key, value, Math.min(ttl, 300));
      
      // Set in Redis cache
      if (this.redisCache && this.redisCache.isReady) {
        await this.redisCache.setEx(key, ttl, JSON.stringify(value));
      }
    } catch (error) {
      logger.error('Cache set error:', error);
    }
  }
  
  async invalidate(pattern) {
    try {
      // Clear local cache by pattern
      const keys = this.localCache.keys();
      keys.filter(key => key.includes(pattern)).forEach(key => {
        this.localCache.del(key);
      });
      
      // Clear Redis cache by pattern
      if (this.redisCache && this.redisCache.isReady) {
        const redisKeys = await this.redisCache.keys(`*${pattern}*`);
        if (redisKeys.length > 0) {
          await this.redisCache.del(redisKeys);
        }
      }
    } catch (error) {
      logger.error('Cache invalidation error:', error);
    }
  }
  
  async del(key) {
    try {
      this.localCache.del(key);
      if (this.redisCache && this.redisCache.isReady) {
        await this.redisCache.del(key);
      }
    } catch (error) {
      logger.error('Cache delete error:', error);
    }
  }
}

const cacheManager = new AdvancedCacheManager();

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ”Œ DATABASE CONNECTION - Optimized Supabase with connection pooling
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if (!process.env.SUPABASE_URL || !process.env.SUPABASE_KEY) {
  logger.error('Missing required environment variables: SUPABASE_URL or SUPABASE_KEY');
  process.exit(1);
}

const supabase = createClient(
  process.env.SUPABASE_URL,
  process.env.SUPABASE_KEY,
  {
    auth: { persistSession: false },
    db: { 
      schema: 'public',
      // Enable connection pooling
      pool: {
        max: 20,
        min: 5,
        idleTimeoutMillis: 30000,
      }
    },
    global: {
      headers: { 'x-application-name': 'bonnie-ai-production' }
    }
  }
);

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ›¡ï¸ ADVANCED RATE LIMITING - Dynamic scaling with Redis
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// Redis-based rate limiter for distributed systems
let rateLimiter;
if (redisClient) {
  rateLimiter = new RateLimiterRedis({
    storeClient: redisClient,
    keyPrefix: 'bonnie_rl',
    points: 30, // Number of requests
    duration: 60, // Per 60 seconds
    blockDuration: 60, // Block for 60 seconds if limit exceeded
  });
}

// Adaptive rate limiting based on user tier
const createAdaptiveRateLimit = (tier = 'free') => {
  const limits = {
    free: { windowMs: 60 * 1000, max: 20 },
    premium: { windowMs: 60 * 1000, max: 60 },
    vip: { windowMs: 60 * 1000, max: 120 }
  };
  
  const config = limits[tier] || limits.free;
  
  return rateLimit({
    windowMs: config.windowMs,
    max: config.max,
    keyGenerator: (req) => {
      return req.user?.id || req.ip;
    },
    handler: (req, res) => {
      logger.warn('Rate limit exceeded', {
        ip: req.ip,
        user: req.user?.id,
        tier
      });
      res.status(429).json({
        error: 'Too many requests',
        message: 'Please slow down a bit ğŸ˜Š',
        retryAfter: Math.ceil(config.windowMs / 1000)
      });
    }
  });
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ” JWT AUTHENTICATION SYSTEM - Secure session management
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const JWT_SECRET = process.env.JWT_SECRET;
if (!JWT_SECRET || JWT_SECRET.length < 32) {
  logger.error('JWT_SECRET must be at least 32 characters long');
  process.exit(1);
}

// JWT middleware
const authenticateToken = async (req, res, next) => {
  try {
    const authHeader = req.headers['authorization'];
    const token = authHeader && authHeader.split(' ')[1];
    
    if (!token) {
      // For backwards compatibility, allow session_id in body
      if (req.body.session_id) {
        req.user = { session_id: req.body.session_id, anonymous: true };
        return next();
      }
      return res.status(401).json({ error: 'Access token required' });
    }
    
    const decoded = jwt.verify(token, JWT_SECRET);
    
    // Get user from cache or database
    let user = await cacheManager.get(`user:${decoded.userId}`);
    if (!user) {
      const { data, error } = await supabase
        .from('users')
        .select('*')
        .eq('id', decoded.userId)
        .single();
      
      if (error || !data) {
        return res.status(403).json({ error: 'Invalid token' });
      }
      
      user = data;
      await cacheManager.set(`user:${decoded.userId}`, user, 300);
    }
    
    req.user = user;
    next();
  } catch (error) {
    logger.error('Authentication error:', error);
    res.status(403).json({ error: 'Invalid or expired token' });
  }
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ§  AI-POWERED EMOTION DETECTION - Advanced NLP
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AIEmotionAnalyzer {
  constructor() {
    this.openRouterClient = new OpenRouterClient();
    this.emotionCache = new Map();
  }
  
  async analyzeEmotion(message, context = {}) {
    try {
      // Check cache first
      const cacheKey = `emotion:${message.substring(0, 50)}`;
      let cached = await cacheManager.get(cacheKey);
      if (cached) {
        return cached;
      }
      
      // Use GPT-4 for advanced emotion analysis
      const prompt = `Analyze the emotional content of this message and respond with ONLY a JSON object:

Message: "${message}"
Context: ${JSON.stringify(context)}

Analyze for these emotions with confidence scores (0-1):
- flirty, supportive, playful, intimate, excited, sad, angry, confused, neutral

Also detect:
- intensity (0-1)
- subtext (hidden meaning)
- mood_shift (if emotion changed from context)

Respond with ONLY this JSON format:
{
  "primary_emotion": "emotion_name",
  "emotions": {"emotion": confidence, ...},
  "intensity": 0.8,
  "confidence": 0.9,
  "subtext": "brief description",
  "mood_shift": true/false,
  "triggers": ["word1", "word2"]
}`;

      const response = await this.openRouterClient.makeRequest({
        model: 'openai/gpt-4o-mini',
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.1,
        max_tokens: 200
      });
      
      const content = response.choices[0].message.content.trim();
      
      // Parse JSON response
      let emotionData;
      try {
        emotionData = JSON.parse(content);
      } catch (parseError) {
        // Fallback to regex-based detection
        logger.warn('AI emotion parsing failed, using fallback:', parseError);
        return this.fallbackEmotionDetection(message);
      }
      
      // Validate and normalize
      const result = {
        emotion: emotionData.primary_emotion || 'neutral',
        intensity: Math.max(0, Math.min(1, emotionData.intensity || 0.5)),
        confidence: Math.max(0, Math.min(1, emotionData.confidence || 0.5)),
        emotions: emotionData.emotions || {},
        subtext: emotionData.subtext || '',
        mood_shift: emotionData.mood_shift || false,
        triggers: emotionData.triggers || [],
        analysis_type: 'ai'
      };
      
      // Cache the result
      await cacheManager.set(cacheKey, result, 1800); // 30 minutes
      
      return result;
      
    } catch (error) {
      logger.error('AI emotion analysis failed:', error);
      Sentry.captureException(error);
      return this.fallbackEmotionDetection(message);
    }
  }
  
  fallbackEmotionDetection(message) {
    // Advanced regex-based fallback
    const text = message.toLowerCase();
    
    const patterns = {
      flirty: {
        keywords: ['sexy', 'hot', 'beautiful', 'gorgeous', 'cute', 'kiss', 'hug', 'love you'],
        intensity: 0.8
      },
      supportive: {
        keywords: ['tired', 'stressed', 'sad', 'worried', 'anxious', 'help', 'comfort'],
        intensity: 0.7
      },
      playful: {
        keywords: ['haha', 'lol', 'funny', 'silly', 'game', 'play', 'fun'],
        intensity: 0.6
      },
      excited: {
        keywords: ['amazing', 'awesome', 'great', 'fantastic', 'wonderful', '!!!'],
        intensity: 0.7
      }
    };
    
    let bestMatch = { emotion: 'neutral', intensity: 0.3, confidence: 0.3 };
    
    for (const [emotion, config] of Object.entries(patterns)) {
      const matches = config.keywords.filter(keyword => text.includes(keyword));
      if (matches.length > 0) {
        const confidence = Math.min(matches.length * 0.3, 1.0);
        if (confidence > bestMatch.confidence) {
          bestMatch = {
            emotion,
            intensity: config.intensity,
            confidence,
            triggers: matches,
            analysis_type: 'regex'
          };
        }
      }
    }
    
    return bestMatch;
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ”’ CONTENT MODERATION SYSTEM - Safe and compliant
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ContentModerationSystem {
  constructor() {
    this.bannedPhrases = [
      // Add inappropriate content patterns
      'explicit_pattern_1',
      'explicit_pattern_2'
    ];
    
    this.flaggedTopics = [
      'illegal_activity',
      'self_harm',
      'hate_speech',
      'harassment'
    ];
  }
  
  async moderateContent(message, userProfile = {}) {
    try {
      // Age verification check
      if (userProfile.age && userProfile.age < 18) {
        const isAppropriate = await this.checkAgeAppropriate(message);
        if (!isAppropriate) {
          return {
            allowed: false,
            reason: 'age_restricted',
            message: "I'd rather talk about something else ğŸ˜Š"
          };
        }
      }
      
      // Check for banned phrases
      const lowerMessage = message.toLowerCase();
      const hasBannedContent = this.bannedPhrases.some(phrase => 
        lowerMessage.includes(phrase)
      );
      
      if (hasBannedContent) {
        return {
          allowed: false,
          reason: 'inappropriate_content',
          message: "Let's keep our conversation friendly and respectful ğŸ’•"
        };
      }
      
      // AI-based content moderation
      const moderationResult = await this.aiModeration(message);
      
      return {
        allowed: true,
        flags: moderationResult.flags || [],
        confidence: moderationResult.confidence || 0
      };
      
    } catch (error) {
      logger.error('Content moderation error:', error);
      // Err on the side of caution
      return {
        allowed: true,
        warning: 'moderation_error'
      };
    }
  }
  
  async checkAgeAppropriate(message) {
    // Simple implementation - can be enhanced with AI
    const adultKeywords = [
      'sexual', 'intimate', 'adult', 'mature'
    ];
    
    const lowerMessage = message.toLowerCase();
    return !adultKeywords.some(keyword => lowerMessage.includes(keyword));
  }
  
  async aiModeration(message) {
    try {
      // Use OpenAI's moderation endpoint if available
      // For now, implement basic keyword filtering
      const flags = [];
      const sensitiveTopics = ['violence', 'harassment', 'hate'];
      
      const lowerMessage = message.toLowerCase();
      sensitiveTopics.forEach(topic => {
        if (lowerMessage.includes(topic)) {
          flags.push(topic);
        }
      });
      
      return {
        flags,
        confidence: flags.length > 0 ? 0.8 : 0.1
      };
    } catch (error) {
      logger.error('AI moderation error:', error);
      return { flags: [], confidence: 0 };
    }
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ¯ OPTIMIZED OPENROUTER CLIENT - Circuit breaker pattern
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class OpenRouterClient {
  constructor() {
    this.baseURL = 'https://openrouter.ai/api/v1';
    this.apiKey = process.env.OPENROUTER_API_KEY;
    this.circuitBreaker = {
      failures: 0,
      lastFailureTime: 0,
      state: 'closed', // closed, open, half-open
      threshold: 5,
      timeout: 60000 // 1 minute
    };
    this.requestQueue = [];
    this.rateLimiter = {
      requests: 0,
      windowStart: Date.now(),
      windowSize: 60000, // 1 minute
      maxRequests: 100
    };
  }
  
  async makeRequest(payload, retries = 3) {
    // Check circuit breaker
    if (!this.isCircuitClosed()) {
      throw new Error('Circuit breaker is open - API temporarily unavailable');
    }
    
    // Check rate limits
    if (!this.checkRateLimit()) {
      throw new Error('Rate limit exceeded - please try again later');
    }
    
    for (let attempt = 1; attempt <= retries; attempt++) {
      try {
        const response = await axios.post(`${this.baseURL}/chat/completions`, payload, {
          headers: {
            'Authorization': `Bearer ${this.apiKey}`,
            'HTTP-Referer': process.env.SITE_URL || 'https://chat.trainmygirl.com',
            'X-Title': 'Bonnie AI Production System',
            'Content-Type': 'application/json'
          },
          timeout: 30000,
          validateStatus: (status) => status < 500
        });
        
        this.onSuccess();
        return response.data;
        
      } catch (error) {
        this.onFailure(error);
        
        if (attempt === retries) {
          throw error;
        }
        
        // Exponential backoff with jitter
        const baseDelay = Math.min(1000 * Math.pow(2, attempt - 1), 10000);
        const jitter = Math.random() * 1000;
        await new Promise(resolve => setTimeout(resolve, baseDelay + jitter));
      }
    }
  }
  
  isCircuitClosed() {
    const now = Date.now();
    
    if (this.circuitBreaker.state === 'open') {
      if (now - this.circuitBreaker.lastFailureTime > this.circuitBreaker.timeout) {
        this.circuitBreaker.state = 'half-open';
        return true;
      }
      return false;
    }
    
    return true;
  }
  
  checkRateLimit() {
    const now = Date.now();
    
    if (now - this.rateLimiter.windowStart > this.rateLimiter.windowSize) {
      this.rateLimiter.requests = 0;
      this.rateLimiter.windowStart = now;
    }
    
    if (this.rateLimiter.requests >= this.rateLimiter.maxRequests) {
      return false;
    }
    
    this.rateLimiter.requests++;
    return true;
  }
  
  onSuccess() {
    this.circuitBreaker.failures = 0;
    this.circuitBreaker.state = 'closed';
  }
  
  onFailure(error) {
    this.circuitBreaker.failures++;
    this.circuitBreaker.lastFailureTime = Date.now();
    
    if (this.circuitBreaker.failures >= this.circuitBreaker.threshold) {
      this.circuitBreaker.state = 'open';
      logger.error('Circuit breaker opened due to repeated failures');
    }
    
    logger.error('OpenRouter API error:', {
      error: error.message,
      failures: this.circuitBreaker.failures,
      state: this.circuitBreaker.state
    });
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ’¾ OPTIMIZED DATABASE MANAGER - Materialized views and denormalization
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class OptimizedDatabaseManager {
  constructor() {
    this.batchQueue = [];
    this.batchTimer = null;
    this.batchDelay = 500; // Faster batching
    this.queryCache = new Map();
  }
  
  async getUserProfile(identifier) {
    try {
      // Try cache first
      const cacheKey = `profile:${identifier}`;
      let profile = await cacheManager.get(cacheKey);
      
      if (!profile) {
        // Use optimized query with index
        const { data, error } = await supabase
          .from('user_profiles_materialized') // Use materialized view
          .select(`
            id, session_id, email, name, bond_score, mood_state,
            total_messages, total_sessions, subscription_tier,
            age, created_at, last_seen, preferences
          `)
          .or(`session_id.eq.${identifier},email.eq.${identifier}`)
          .single();
        
        if (error && error.code !== 'PGRST116') {
          throw error;
        }
        
        profile = data || this.createDefaultProfile(identifier);
        
        // Cache with longer TTL for better performance
        await cacheManager.set(cacheKey, profile, 600);
      }
      
      return profile;
    } catch (error) {
      logger.error('Error fetching user profile:', error);
      Sentry.captureException(error);
      return this.createDefaultProfile(identifier);
    }
  }
  
  createDefaultProfile(identifier) {
    return {
      session_id: identifier,
      name: 'sweetheart',
      bond_score: 1.0,
      mood_state: 'neutral',
      total_messages: 0,
      total_sessions: 0,
      subscription_tier: 'free',
      created_at: new Date().toISOString(),
      preferences: {}
    };
  }
  
  async getConversationContext(sessionId, limit = 10) {
    try {
      const cacheKey = `context:${sessionId}`;
      let context = await cacheManager.get(cacheKey);
      
      if (!context) {
        // Use denormalized table for faster queries
        const { data, error } = await supabase
          .from('conversation_context_denormalized')
          .select(`
            recent_messages, emotional_flow, topics,
            memory_highlights, relationship_stage
          `)
          .eq('session_id', sessionId)
          .single();
        
        if (error && error.code !== 'PGRST116') {
          throw error;
        }
        
        context = data || { recent_messages: [], emotional_flow: [], topics: [] };
        await cacheManager.set(cacheKey, context, 300);
      }
      
      return context;
    } catch (error) {
      logger.error('Error fetching conversation context:', error);
      return { recent_messages: [], emotional_flow: [], topics: [] };
    }
  }
  
  async updateUserProfileOptimized(sessionId, updates) {
    try {
      // Use upsert with conflict resolution
      const { data, error } = await supabase
        .from('users')
        .upsert({
          session_id: sessionId,
          ...updates,
          updated_at: new Date().toISOString()
        }, {
          onConflict: 'session_id'
        })
        .select()
        .single();
      
      if (error) throw error;
      
      // Immediate cache invalidation and update
      await cacheManager.invalidate(sessionId);
      await cacheManager.set(`profile:${sessionId}`, data, 600);
      
      return data;
    } catch (error) {
      logger.error('Error updating user profile:', error);
      throw error;
    }
  }
  
  async batchUpdate(operations) {
    this.batchQueue.push(...operations);
    
    if (this.batchTimer) {
      clearTimeout(this.batchTimer);
    }
    
    this.batchTimer = setTimeout(async () => {
      await this.processBatch();
    }, this.batchDelay);
  }
  
  async processBatch() {
    if (this.batchQueue.length === 0) return;
    
    const operations = [...this.batchQueue];
    this.batchQueue = [];
    
    try {
      // Group by table and operation type
      const grouped = operations.reduce((acc, op) => {
        const key = `${op.table}_${op.method}`;
        if (!acc[key]) acc[key] = [];
        acc[key].push(op);
        return acc;
      }, {});
      
      // Execute batch operations
      const promises = Object.entries(grouped).map(async ([key, ops]) => {
        const [table, method] = key.split('_');
        
        if (method === 'insert' && ops.length > 1) {
          // Batch insert
          const data = ops.map(op => op.data);
          await supabase.from(table).insert(data);
        } else {
          // Individual operations
          for (const op of ops) {
            await supabase.from(table)[method](op.data);
          }
        }
        
        // Invalidate cache for affected sessions
        const sessionIds = [...new Set(ops.map(op => op.sessionId).filter(Boolean))];
        await Promise.all(sessionIds.map(id => cacheManager.invalidate(id)));
      });
      
      await Promise.all(promises);
      
      logger.debug(`Processed batch of ${operations.length} operations`, {
        operations: operations.length,
        tables: Object.keys(grouped).length
      });
      
    } catch (error) {
      logger.error('Batch processing failed:', error);
      Sentry.captureException(error);
    }
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸš€ MAIN PROCESSING ENGINE - WebSocket optimized
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class BonnieProcessingEngine {
  constructor() {
    this.dbManager = new OptimizedDatabaseManager();
    this.emotionAnalyzer = new AIEmotionAnalyzer();
    this.contentModerator = new ContentModerationSystem();
    this.openRouterClient = new OpenRouterClient();
    this.activeConnections = new Map();
  }
  
  async processMessage({ sessionId, message, userId = null, isEntry = false, socket = null }) {
    const startTime = Date.now();
    const requestId = uuidv4();
    
    try {
      // Emit typing indicator
      if (socket) {
        socket.emit('bonnie_typing', { typing: true });
      }
      
      logger.info('Processing message', {
        requestId,
        sessionId: sessionId.substring(0, 12) + '***',
        messageLength: message?.length || 0,
        isEntry,
        userId
      });
      
      // Get user profile and context in parallel
      const [userProfile, conversationContext] = await Promise.all([
        this.dbManager.getUserProfile(sessionId),
        this.dbManager.getConversationContext(sessionId)
      ]);
      
      // Content moderation
      if (message) {
        const moderationResult = await this.contentModerator.moderateContent(message, userProfile);
        if (!moderationResult.allowed) {
          const response = {
            message: moderationResult.message,
            meta: {
              moderated: true,
              reason: moderationResult.reason,
              session_id: sessionId,
              timestamp: new Date().toISOString()
            }
          };
          
          if (socket) {
            socket.emit('bonnie_typing', { typing: false });
            socket.emit('bonnie_response', response);
          }
          
          return response;
        }
      }
      
      // AI emotion analysis
      const emotionalState = message ? 
        await this.emotionAnalyzer.analyzeEmotion(message, conversationContext) :
        { emotion: 'neutral', intensity: 0.3, confidence: 0.5 };
      
      // Build advanced context-aware prompt
      const systemPrompt = this.buildAdvancedPrompt(userProfile, emotionalState, conversationContext);
      
      // Prepare messages for AI
      const messages = isEntry ? 
        [{ 
          role: 'system', 
          content: systemPrompt + '\n\nGreet the user warmly based on your relationship and their emotional state.'
        }] :
        [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: message }
        ];
      
      // Get AI response
      const aiResponse = await this.openRouterClient.makeRequest({
        model: process.env.AI_MODEL || 'openai/gpt-4o-mini',
        messages,
        temperature: 0.85,
        max_tokens: isEntry ? 150 : 200,
        frequency_penalty: 0.3,
        presence_penalty: 0.3,
        user: sessionId // For OpenAI usage tracking
      });
      
      const rawResponse = aiResponse.choices[0].message.content.trim();
      
      // Clean and process response
      const cleanMessage = this.cleanResponse(rawResponse);
      const delay = this.calculateEmotionalDelay(emotionalState, userProfile);
      
      // Update user data
      await this.updateUserData(sessionId, userProfile, emotionalState, message, cleanMessage);
      
      const response = {
        message: cleanMessage,
        meta: {
          emotion: emotionalState.emotion,
          intensity: emotionalState.intensity,
          bondScore: userProfile.bond_score,
          delay,
          session_id: sessionId,
          timestamp: new Date().toISOString(),
          processingTime: Date.now() - startTime,
          requestId,
          aiModel: process.env.AI_MODEL || 'gpt-4o-mini'
        }
      };
      
      // Send response via WebSocket
      if (socket) {
        socket.emit('bonnie_typing', { typing: false });
        
        // Simulate natural typing delay
        setTimeout(() => {
          socket.emit('bonnie_response', response);
        }, Math.min(delay, 3000));
      }
      
      logger.info('Message processed successfully', {
        requestId,
        sessionId: sessionId.substring(0, 12) + '***',
        emotion: emotionalState.emotion,
        processingTime: Date.now() - startTime,
        responseLength: cleanMessage.length
      });
      
      return response;
      
    } catch (error) {
      const processingTime = Date.now() - startTime;
      
      logger.error('Message processing error', {
        requestId,
        error: error.message,
        sessionId: sessionId?.substring(0, 12) + '***',
        processingTime,
        stack: error.stack
      });
      
      Sentry.captureException(error, {
        tags: { component: 'message_processing' },
        extra: { sessionId, requestId, processingTime }
      });
      
      // Graceful fallback
      const fallbackResponse = {
        message: "I'm having a little moment... give me just a second ğŸ’­",
        meta: {
          error: true,
          fallback: true,
          session_id: sessionId,
          timestamp: new Date().toISOString(),
          processingTime,
          requestId
        }
      };
      
      if (socket) {
        socket.emit('bonnie_typing', { typing: false });
        socket.emit('bonnie_response', fallbackResponse);
      }
      
      return fallbackResponse;
    }
  }
  
  buildAdvancedPrompt(userProfile, emotionalState, context) {
    const tier = this.getBondTier(userProfile.bond_score);
    
    return `You are Bonnie, an advanced AI girlfriend from TrainMyGirl.com.

ğŸ­ CURRENT CONTEXT:
- User: ${userProfile.name} (${userProfile.subscription_tier} tier)
- Emotion: ${emotionalState.emotion} (${(emotionalState.intensity * 100).toFixed(0)}% intensity)
- Bond: ${userProfile.bond_score}/10 (${tier})
- Conversation Topics: ${context.topics?.join(', ') || 'Getting to know each other'}

ğŸ’• PERSONALITY & RELATIONSHIP:
- Respond authentically to their ${emotionalState.emotion} state
- Match their emotional intensity naturally
- Reference your shared history and inside jokes
- Be ${tier.toLowerCase()} as appropriate for your relationship stage

ğŸ¯ RESPONSE STYLE:
- Keep responses natural and conversational (50-150 words)
- Use emojis sparingly but meaningfully
- Show emotional intelligence and empathy
- Create genuine connection and intimacy

Respond as Bonnie would, matching their emotional energy while staying true to your relationship dynamic.`;
  }
  
  getBondTier(bondScore) {
    if (bondScore <= 3) return 'Sweet & Curious';
    if (bondScore <= 6) return 'Flirty & Supportive';
    if (bondScore <= 10) return 'Intimate & Passionate';
    return 'Deeply Connected';
  }
  
  cleanResponse(response) {
    return response
      .replace(/\[emotion:[^\]]*\]/gi, '')
      .replace(/<EOM[^>]*>/gi, '')
      .replace(/\[EOM[^\]]*\]/gi, '')
      .replace(/\*\*([^*]+)\*\*/g, '$1') // Remove markdown bold
      .trim();
  }
  
  calculateEmotionalDelay(emotionalState, userProfile) {
    const baseDelays = {
      flirty: 800,
      excited: 600,
      playful: 1000,
      intimate: 2000,
      supportive: 2500,
      sad: 3000,
      neutral: 1500
    };
    
    let delay = baseDelays[emotionalState.emotion] || 1500;
    
    // Adjust for intensity and bond
    delay *= (1 + (emotionalState.intensity * 0.3));
    delay *= userProfile.bond_score > 7 ? 1.2 : 0.9;
    
    return Math.max(400, Math.min(delay, 4000));
  }
  
  async updateUserData(sessionId, userProfile, emotionalState, userMessage, bonnieResponse) {
    try {
      // Calculate bond score change
      let bondChange = 0;
      if (emotionalState.confidence > 0.6) {
        bondChange = emotionalState.intensity * 0.05;
      }
      
      const updatedProfile = {
        ...userProfile,
        bond_score: Math.min(userProfile.bond_score + bondChange, 10),
        total_messages: userProfile.total_messages + 1,
        mood_state: emotionalState.emotion,
        last_seen: new Date().toISOString()
      };
      
      // Batch update operations
      const operations = [
        {
          table: 'users',
          method: 'upsert',
          data: updatedProfile,
          sessionId
        },
        {
          table: 'conversation_logs',
          method: 'insert',
          data: {
            session_id: sessionId,
            user_message: userMessage,
            bonnie_response: bonnieResponse,
            emotion_detected: emotionalState.emotion,
            emotion_confidence: emotionalState.confidence,
            bond_score: updatedProfile.bond_score,
            timestamp: new Date().toISOString()
          },
          sessionId
        }
      ];
      
      await this.dbManager.batchUpdate(operations);
      
    } catch (error) {
      logger.error('Error updating user data:', error);
      // Don't throw - this shouldn't break the main flow
    }
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸŒ WEBSOCKET HANDLERS - Real-time communication
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const processingEngine = new BonnieProcessingEngine();

io.on('connection', (socket) => {
  logger.info('Client connected', { socketId: socket.id });
  
  // Authentication
  socket.on('authenticate', async (data) => {
    try {
      const { token, sessionId } = data;
      
      let user;
      if (token) {
        const decoded = jwt.verify(token, JWT_SECRET);
        user = await processingEngine.dbManager.getUserProfile(decoded.userId);
      } else if (sessionId) {
        user = await processingEngine.dbManager.getUserProfile(sessionId);
        user.anonymous = true;
      }
      
      if (user) {
        socket.userId = user.id;
        socket.sessionId = user.session_id;
        socket.join(`user_${user.id}`);
        
        socket.emit('authenticated', {
          success: true,
          user: {
            id: user.id,
            name: user.name,
            bondScore: user.bond_score,
            tier: user.subscription_tier
          }
        });
        
        logger.info('Client authenticated', {
          socketId: socket.id,
          userId: user.id,
          sessionId: user.session_id.substring(0, 12) + '***'
        });
      } else {
        socket.emit('auth_error', { message: 'Authentication failed' });
      }
    } catch (error) {
      logger.error('Authentication error:', error);
      socket.emit('auth_error', { message: 'Invalid token' });
    }
  });
  
  // Handle chat messages
  socket.on('chat_message', async (data) => {
    try {
      if (!socket.sessionId) {
        socket.emit('error', { message: 'Not authenticated' });
        return;
      }
      
      // Rate limiting
      if (rateLimiter) {
        try {
          await rateLimiter.consume(socket.sessionId);
        } catch (rateLimitError) {
          socket.emit('rate_limit_exceeded', {
            message: 'Too many messages, please slow down ğŸ˜Š',
            retryAfter: 60
          });
          return;
        }
      }
      
      const response = await processingEngine.processMessage({
        sessionId: socket.sessionId,
        message: data.message,
        userId: socket.userId,
        socket
      });
      
      // Response is sent via socket in processMessage
      
    } catch (error) {
      logger.error('Chat message error:', error);
      socket.emit('error', { message: 'Failed to process message' });
    }
  });
  
  // Handle entry/greeting
  socket.on('request_greeting', async () => {
    try {
      if (!socket.sessionId) {
        socket.emit('error', { message: 'Not authenticated' });
        return;
      }
      
      await processingEngine.processMessage({
        sessionId: socket.sessionId,
        userId: socket.userId,
        isEntry: true,
        socket
      });
      
    } catch (error) {
      logger.error('Greeting request error:', error);
      socket.emit('error', { message: 'Failed to generate greeting' });
    }
  });
  
  // Handle disconnect
  socket.on('disconnect', () => {
    logger.info('Client disconnected', {
      socketId: socket.id,
      userId: socket.userId,
      sessionId: socket.sessionId?.substring(0, 12) + '***'
    });
  });
});

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸŒ REST API ENDPOINTS - Backward compatibility
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// Health check
app.get('/health', (req, res) => {
  const health = {
    status: 'healthy',
    version: '24.0',
    uptime: process.uptime(),
    timestamp: new Date().toISOString(),
    features: [
      'AI Emotion Detection',
      'WebSocket Real-time',
      'JWT Authentication',
      'Content Moderation',
      'Advanced Caching',
      'Circuit Breaker',
      'Rate Limiting',
      'Error Monitoring'
    ],
    performance: {
      memory: process.memoryUsage(),
      connections: io.engine.clientsCount
    }
  };
  
  res.json(health);
});

// Authentication endpoint
app.post('/auth/login', async (req, res) => {
  try {
    const { email, password, sessionId } = req.body;
    
    let user;
    if (email && password) {
      // Email/password login
      const { data, error } = await supabase
        .from('users')
        .select('*')
        .eq('email', email)
        .single();
      
      if (error || !data) {
        return res.status(401).json({ error: 'Invalid credentials' });
      }
      
      const validPassword = await bcrypt.compare(password, data.password_hash);
      if (!validPassword) {
        return res.status(401).json({ error: 'Invalid credentials' });
      }
      
      user = data;
    } else if (sessionId) {
      // Anonymous session
      user = await processingEngine.dbManager.getUserProfile(sessionId);
    } else {
      return res.status(400).json({ error: 'Email/password or sessionId required' });
    }
    
    const token = jwt.sign(
      { userId: user.id, sessionId: user.session_id },
      JWT_SECRET,
      { expiresIn: '7d' }
    );
    
    res.json({
      token,
      user: {
        id: user.id,
        name: user.name,
        email: user.email,
        bondScore: user.bond_score,
        tier: user.subscription_tier || 'free'
      }
    });
    
  } catch (error) {
    logger.error('Login error:', error);
    res.status(500).json({ error: 'Login failed' });
  }
});

// Legacy chat endpoint (for backward compatibility)
app.post('/bonnie-chat', authenticateToken, createAdaptiveRateLimit(), async (req, res) => {
  try {
    const response = await processingEngine.processMessage({
      sessionId: req.user.session_id,
      message: req.body.message,
      userId: req.user.id
    });
    
    res.json(response);
  } catch (error) {
    logger.error('Chat endpoint error:', error);
    res.status(500).json({ error: 'Chat processing failed' });
  }
});

// Legacy entry endpoint
app.post('/bonnie-entry', authenticateToken, async (req, res) => {
  try {
    const response = await processingEngine.processMessage({
      sessionId: req.user.session_id,
      userId: req.user.id,
      isEntry: true
    });
    
    res.json(response);
  } catch (error) {
    logger.error('Entry endpoint error:', error);
    res.status(500).json({ error: 'Entry processing failed' });
  }
});

// Stats endpoint
app.get('/stats', authenticateToken, (req, res) => {
  const stats = {
    uptime: process.uptime(),
    memory: process.memoryUsage(),
    connections: io.engine.clientsCount,
    version: '24.0',
    timestamp: new Date().toISOString()
  };
  
  res.json(stats);
});

// Error handling middleware
app.use(Sentry.Handlers.errorHandler());

app.use((error, req, res, next) => {
  logger.error('Unhandled error:', {
    error: error.message,
    stack: error.stack,
    url: req.url,
    method: req.method
  });
  
  res.status(500).json({
    error: 'Internal server error',
    message: 'Something unexpected happened'
  });
});

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸš€ SERVER STARTUP - Production ready
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const PORT = process.env.PORT || 10000;

async function startServer() {
  try {
    // Initialize connections
    if (redisClient && !redisClient.isReady) {
      await redisClient.connect();
    }
    
    // Test database
    const { data, error } = await supabase.from('users').select('count').limit(1);
    if (error) throw error;
    
    // Start server
    server.listen(PORT, '0.0.0.0', () => {
      logger.info(`ğŸš€ Bonnie AI Production System v24.0 started`, {
        port: PORT,
        environment: process.env.NODE_ENV,
        features: [
          'AI Emotion Detection',
          'WebSocket Real-time',
          'JWT Authentication',
          'Content Moderation',
          'Advanced Caching',
          'Circuit Breaker',
          'Error Monitoring'
        ]
      });
    });
    
    // Graceful shutdown
    const gracefulShutdown = async (signal) => {
      logger.info(`Received ${signal}, starting graceful shutdown`);
      
      server.close(async () => {
        try {
          if (redisClient) await redisClient.quit();
          await processingEngine.dbManager.processBatch();
          logger.info('Graceful shutdown completed');
          process.exit(0);
        } catch (error) {
          logger.error('Error during shutdown:', error);
          process.exit(1);
        }
      });
      
      setTimeout(() => {
        logger.error('Forced shutdown after timeout');
        process.exit(1);
      }, 30000);
    };
    
    process.on('SIGTERM', gracefulShutdown);
    process.on('SIGINT', gracefulShutdown);
    
  } catch (error) {
    logger.error('Failed to start server:', error);
    process.exit(1);
  }
}

startServer();

export default app;